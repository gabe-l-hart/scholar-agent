# Prompting

This readme serves as a scratch pad for writing down prompts used during the creation of this project.

## AI assistant setup

- Continue.dev w/ `gpt-oss:20b` and 128k context length
  - Optionally w/ Granite 4 tiny prerelease
- GitHub MCP server `mcp/github`

## Project Description

I'm building a project that is designed to be a scholar agent. The scholar agent will primarily have a chat interface, but will also have an optional UI (possibly a terminal UI as well) for navigating documents during research. The agent will have two primary logical entrypoints:

1. A user submits a document (PDF, Word, etc) and optionally a prompt on their goal for the paper

2. A user starts with a prompt about a research topic

If (2), the system first does a literature search to find relevant papers or other documents related to the prompt. The user can then select a single document to dig further in (arriving at (1)).

Once the user has selected a paper as a starting point, the system will perform the following:

1. Summarize the overall findings of the paper and the novel contribution

2. Identify the key areas of background that a reader would need to understand in order to fully understand the paper

The system will then present the summary and upstream topics to the user. The user can then engage in free-form chat-with-documents. If the user's query results in asking for deeper information on one of the background topics, the system will start background research (similar to entrypoint (2) above).

Each atomic interaction with the agent will constitute a Session. The agent will have isolated memory for each session, allowing the user to operate independently for a given session. The agent will also retain two other tiers of memory:

1. User memory: During a session, a user can opt to explicitly tell the agent to remember pieces for later. The agent can also prompt the user that a given piece of information would be good to save for later.

2. System memory: Overall knowledge of the literature can be shared across users and sessions if the user allows it during a session's configuration.

FIRST TASK:

The first thing I need you to do is help outline the key components of this agent. I have some thoughts and ideas, but I'd like to hear your thoughts first.

### Follow up 1

Alright, this is a great start. There are a couple of specific pieces of technology I plan to use already:

- For document conversion, I plan to use Docling via docling-mcp (https://github.com/docling-project/docling-mcp)

- I play to use python 3.11+

- I plan to use a standard `pyproject.toml` for project configuration

- I plan to use `alchemy-logging` / `alog` (https://pypi.org/project/alchemy-logging/) as the wrapper logging framework for configuration and formatting

- I plan to use `alchemy-config` / `aconfig` (https://pypi.org/project/alchemy-config/) for configuration (config file w/ environment overrides)

- I plan to, as much as possible, keep the individual components abstract using the factory pattern to instantiate the appropriate instance for each component. You can find an example of the factory pattern at https://github.com/caikit/caikit/blob/main/caikit/core/toolkit/factory.py. It is implemented using `aconfig` and `alog`, but has some custom error handling logic in the larger `caikit` project that I don't want to pull in.

- For the core LLM, I plan to make local models the default with the ability to select remote models as well. I don't want to own the factory for this, though, so I'd like to use an existing library for this. Please prioritize a library with the smallest dependency footprint.

Given these pieces of technology, first I'd like you to set up the project skeleton.
